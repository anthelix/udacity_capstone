{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les bases de données multidimensionnelles considèrent chaque attribut d’une donnée comme une dimension « séparée ». Le logiciel peut ensuite localiser l’intersection des dimensions et les afficher. Il est ainsi possible d’analyser et de comparer les données de différentes façons. Les attributs peuvent aussi être séparés en plusieurs sous-attributs. Les bases de données multi-dimensionnelles s’opposent aux bases de données relationnelles à deux dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!{sys.executable} -m pip install -U ray\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--packages=org.apache.hadoop:hadoop-aws:2.7.3 pyspark-shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "pd.set_option(\"display.precision\", 2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "# set AWS variables\n",
    "os.environ['AWS_ACCESS_KEY_ID']    = config['AWS']['KEY']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = config['AWS']['SECRET']\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import requests\n",
    "\n",
    "download_url = \"https://raw.githubusercontent.com/fivethirtyeight/data/master/nba-elo/nbaallelo.csv\"\n",
    "target_csv_path = \"nba_all_elo.csv\"\n",
    "\n",
    "response = requests.get(download_url)\n",
    "response.raise_for_status()    # Check that the request was successful\n",
    "with open(target_csv_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "print(\"Download ready.\")\n",
    ">>> import pandas as pd\n",
    ">>> nba = pd.read_csv(\"nba_all_elo.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1,2G\r\n",
      "510M airports_us.csv\r\n",
      "509M GlobalLandTemperaturesByCity.csv\r\n",
      "205M WDIData.csv\r\n",
      "5,8M airport-codes_csv.csv\r\n",
      "248K us-cities-demographics.csv\r\n",
      "144K immigration_data_sample.csv\r\n",
      " 36K I94_SAS_Labels_Descriptions.SAS\r\n",
      "4,0K ./\r\n",
      "4,0K ../\r\n",
      "4,0K 20-years-us-university-dataset/\r\n",
      "4,0K airline-delay-and-cancellation-data-2009-2018/\r\n",
      "4,0K education-statistics/\r\n",
      "4,0K sas_data/\r\n"
     ]
    }
   ],
   "source": [
    "# Read in the data here\n",
    "!ls -1FSash ./dataset\n",
    "#!ls -tRFh ./dataset/\n",
    "path = './dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope TODO\n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data TODO\n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immigration data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * U.S. immigration officers\n",
    " * I-94 Form (Arrival/Departure Record) to foreign visitors \n",
    " * Explanation about the Visitor Arrivals Program (I-94 Form) [here](https://travel.trade.gov/research/programs/i94/description.asp)\n",
    " * data about arrival and why and during\n",
    " * dataset = 1 file per month\n",
    " * here: april 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "* immigration_data_sample\n",
    "    * revoir l'orignine du fichier. chercher data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat dans udacity workspace\n",
    "    (pd.read_sas(immigration_fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n",
    "    ==> 1000 rows fourni par udac, beaucoup plus dans 1 seul mois\n",
    "    * DONE: faire un dictionnaire, recuperer les colonnes. \n",
    "* chercher les valeurs manquantes, les valeurs dupliquees, data cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows and 29 columns in dataset immigration provide by Udacity.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 29 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  1000 non-null   int64  \n",
      " 1   cicid       1000 non-null   float64\n",
      " 2   i94yr       1000 non-null   float64\n",
      " 3   i94mon      1000 non-null   float64\n",
      " 4   i94cit      1000 non-null   float64\n",
      " 5   i94res      1000 non-null   float64\n",
      " 6   i94port     1000 non-null   object \n",
      " 7   arrdate     1000 non-null   float64\n",
      " 8   i94mode     1000 non-null   float64\n",
      " 9   i94addr     941 non-null    object \n",
      " 10  depdate     951 non-null    float64\n",
      " 11  i94bir      1000 non-null   float64\n",
      " 12  i94visa     1000 non-null   float64\n",
      " 13  count       1000 non-null   float64\n",
      " 14  dtadfile    1000 non-null   int64  \n",
      " 15  visapost    382 non-null    object \n",
      " 16  occup       4 non-null      object \n",
      " 17  entdepa     1000 non-null   object \n",
      " 18  entdepd     954 non-null    object \n",
      " 19  entdepu     0 non-null      float64\n",
      " 20  matflag     954 non-null    object \n",
      " 21  biryear     1000 non-null   float64\n",
      " 22  dtaddto     1000 non-null   object \n",
      " 23  gender      859 non-null    object \n",
      " 24  insnum      35 non-null     float64\n",
      " 25  airline     967 non-null    object \n",
      " 26  admnum      1000 non-null   float64\n",
      " 27  fltno       992 non-null    object \n",
      " 28  visatype    1000 non-null   object \n",
      "dtypes: float64(15), int64(2), object(12)\n",
      "memory usage: 226.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nRowsRead = 1000 # change and set to None for the whole data\n",
    "description = \"dataset immigration provide by Udacity\"\n",
    "name = \"df_immigration\"\n",
    "file = \"immigration_data_sample.csv\"\n",
    "n_df = pd.read_csv(path+file, nrows = nRowsRead)\n",
    "nRow, nCol = n_df.shape\n",
    "print(\"There are {} rows and {} columns in {}.\".format(nRow, nCol, description))\n",
    "df_immigration = n_df\n",
    "\n",
    "n_df.head(3)\n",
    "print(n_df.info())\n",
    "#dic_6 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Dictionary\n",
    "\n",
    "Column Name | Description | Example | Type\n",
    "-|-|-|-|\n",
    "**cicid**|     ID uniq per record in the dataset | 4.08e+06 | float64\n",
    "**i94yr**|     4 digit year  | 2016.0 | float64\n",
    "**i94mon**|    Numeric month |  4.0 | float64\n",
    "**i94cit**|     3 digit code of source city for immigration (Born country) | 209.0 | float64\n",
    "**i94res**|    3 digit code of source country for immigration (Residence country) | 209.0 | float64\n",
    "**i94port**|   Port addmitted through | HHW | object\n",
    "**arrdate**|   Arrival date in the USA | 20566.0 | float64\n",
    "**i94mode**|   Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported) | 1.0 | float\n",
    "**i94addr**|   State of arrival | HI | object\n",
    "**depdate**|   Departure date | 20573.0 | float\n",
    "**i94bir**|    Age in years | 61.0 | float\n",
    "**i94visa**|   Visa Code - 1 = Business / 2 = Pleasure / 3 = Student |2.0 | float\n",
    "**count**|     Used for summary statistics | 1.0 | float\n",
    "**dtadfile**|  Character Date Field |20160422| int 64 \n",
    "**visapost**|  Department of State where where Visa was issued | | object\n",
    "**occup**|     Occupation that will be performed in U.S. || object\n",
    "**entdepa**|   Arrival Flag - Whether admitted or paroled into the US |G| object\n",
    "**entdepd**|   Departure Flag. Whether departed, lost visa, or deceased |O|  object\n",
    "**entdepu**|   Update Flag - Either apprehended, overstayed, adjusted to perm residence || **float64\n",
    "**matflag**|   Match flag |M|  object\n",
    "**biryear**|   4 digit year of birth |1955.0| float64\n",
    "**dtaddto**|   Character date field to when admitted in the US |07202016| object\n",
    "**gender**|    Gender|M| object\n",
    "**insnum**|    INS number || float64\n",
    "**airline**|   Airline used to arrive in U.S.|JL| object\n",
    "**admnum**|    Admission number, should be unique and not nullable |5.66e+10| float\n",
    "**fltno**|     Flight number of Airline used to arrive in U.S. |00782| object\n",
    "**visatype**|  Class of admission legally admitting the non-immigrant to temporarily stay in U.S.|WT|object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Missing and Duplicate\n",
    "* column `entdepu` has 1000/1000 missing values # Update Flag - Either apprehended, overstayed, adjusted to perm residence\n",
    "* column `occup` has 996/1000 missing value # Occupation that will be performed in U.S.\n",
    "* column `visapost` has 728/1000 missing value # Department of State where where Visa was issued\n",
    "* column `insnum` has 965/1000 missing value # INS number\n",
    "* somme value missing:\n",
    "    * i94addr # US State of arrival 51 unique value\n",
    "    * depdate # Departure date\n",
    "    * entdepd # Departure Flag. Whether departed, lost visa, or deceased\n",
    "    * matflag # Match flag \n",
    "    * gender  # Gender\n",
    "    * airline # Airline used to arrive in U.S\n",
    "    * fltno   # Flight number of Airline used to arrive in U.S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    1000\n",
       "cicid         1000\n",
       "i94yr            1\n",
       "i94mon           1\n",
       "i94cit          88\n",
       "i94res          91\n",
       "i94port         70\n",
       "arrdate         30\n",
       "i94mode          4\n",
       "i94addr         51\n",
       "depdate        109\n",
       "i94bir          85\n",
       "i94visa          3\n",
       "count            1\n",
       "dtadfile        39\n",
       "visapost        97\n",
       "occup            3\n",
       "entdepa          9\n",
       "entdepd         10\n",
       "entdepu          0\n",
       "matflag          1\n",
       "biryear         85\n",
       "dtaddto         99\n",
       "gender           3\n",
       "insnum          29\n",
       "airline        101\n",
       "admnum        1000\n",
       "fltno          502\n",
       "visatype        10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique value in columns\n",
    "n_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i94addr      51\n",
      "depdate     109\n",
      "visapost     97\n",
      "occup         3\n",
      "entdepd      10\n",
      "entdepu       0\n",
      "matflag       1\n",
      "gender        3\n",
      "insnum       29\n",
      "airline     101\n",
      "fltno       502\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>00782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>XBLNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>00464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>DOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>00739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  i94addr  depdate visapost occup entdepd  entdepu matflag gender  insnum  \\\n",
       "0      HI  20573.0      NaN   NaN       O      NaN       M      F     NaN   \n",
       "1      TX  20568.0      MTR   NaN       R      NaN       M      M     NaN   \n",
       "2      FL  20571.0      NaN   NaN       O      NaN       M      M     NaN   \n",
       "3      CA  20581.0      DOH   NaN       O      NaN       M      M     NaN   \n",
       "4      NY  20553.0      NaN   NaN       K      NaN       M      F     NaN   \n",
       "\n",
       "  airline  fltno  \n",
       "0      JL  00782  \n",
       "1     *GA  XBLNG  \n",
       "2      LH  00464  \n",
       "3      QR  00739  \n",
       "4     NaN   LAND  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null value\n",
    "cols = [col for col in n_df.columns if n_df[col].isnull().any()]\n",
    "df_miss = n_df[cols]\n",
    "print(df_miss.nunique())\n",
    "df_miss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, cicid, i94yr, i94mon, i94cit, i94res, i94port, arrdate, i94mode, i94addr, depdate, i94bir, i94visa, count, dtadfile, visapost, occup, entdepa, entdepd, entdepu, matflag, biryear, dtaddto, gender, insnum, airline, admnum, fltno, visatype]\n",
       "Index: []"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup = n_df[n_df.duplicated(keep=False)].sort_values(\"cicid\")\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c/c: we have an ID for each record, `admnum` should be none null as `fltno `, `i94addr` for the analytic questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Land Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data from kaggle\n",
    "* who made it?\n",
    "* this data date about city temperature around the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* ajouter les codes des pays en rapport avec le dataset immigration?\n",
    "* reseigner qui a confectionner les dataset\n",
    "* refaire avec spark, big data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8599212 rows and 7 columns in DataFrame df_temp.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Dtype  \n",
      "---  ------                         -----  \n",
      " 0   dt                             object \n",
      " 1   AverageTemperature             float64\n",
      " 2   AverageTemperatureUncertainty  float64\n",
      " 3   City                           object \n",
      " 4   Country                        object \n",
      " 5   Latitude                       object \n",
      " 6   Longitude                      object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 459.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# download from kaggle the GlobalLandTemperaturesByCity.csv KAGGLE/UDACITY\n",
    "nRowsRead = None # change and set to None for the whole data\n",
    "description = \"download from kaggle the GlobalLandTemperaturesByCity.csv KAGGLE/UDACITY\"\n",
    "name = \"df_temp\"\n",
    "file = \"GlobalLandTemperaturesByCity.csv\"\n",
    "n_df = pd.read_csv(path+file, sep=\",\", nrows = nRowsRead)\n",
    "nRow, nCol = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_temp = n_df\n",
    "\n",
    "print(n_df.info())\n",
    "#n_df.head(3)\n",
    "\n",
    "#dic_2 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Dictionary\n",
    "\n",
    "Column Name | Description | Example | Type\n",
    "-|-|-|-|\n",
    "**dt**|Date format YYYY-MM-DD| 1743-11-01| object\n",
    "**AverageTemperature**|Average Temperature for the city to th date dt|6.07|float64\n",
    "**AverageTemperatureUncertainty**| Average Temperature Uncertainty | 1.74 |float64\n",
    "**City**| City name| Århus| object\n",
    "**Country**| Country name | Denmark | object\n",
    "**Latitude**| Latitude| 57.05N | object\n",
    "**Longitude** | Longitude | 10.33E |object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing and Duplicate\n",
    "* no duplicate for the whole Temperature dataset\n",
    "* 364130 none value for AverageTemperature, so remove this rows if we need temp\n",
    "* begin in 1743 and finis in 2013 so agregation by country and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dt, AverageTemperature, AverageTemperatureUncertainty, City, Country, Latitude, Longitude]\n",
       "Index: []"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup = n_df[n_df.duplicated(keep=False)].sort_values(\"dt\")\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                                 3239\n",
       "AverageTemperature               111994\n",
       "AverageTemperatureUncertainty     10902\n",
       "City                               3448\n",
       "Country                             159\n",
       "Latitude                             73\n",
       "Longitude                          1227\n",
       "dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check number of unique value in columns\n",
    "n_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AverageTemperature               364130\n",
       "AverageTemperatureUncertainty    364130\n",
       "dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [col for col in n_df.columns if n_df[col].isnull().any()]\n",
    "df_miss = n_df[cols]\n",
    "df_miss.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1743-11-01\n",
      "2013-09-01\n"
     ]
    }
   ],
   "source": [
    "n_df.sort_values([\"dt\"], ascending=True, inplace=True)\n",
    "print(n_df[\"dt\"].min())\n",
    "print(n_df[\"dt\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Denmark', 'Bulgaria', 'Poland', 'Romania', 'United Kingdom',\n",
       "       'Czech Republic', 'Montenegro', 'Russia', 'United States',\n",
       "       'Ukraine', 'Portugal', 'Germany', 'Italy', 'Serbia', 'Spain',\n",
       "       'Lithuania', 'France', 'Belarus', 'Canada', 'Netherlands',\n",
       "       'Latvia', 'Croatia', 'Greece', 'Belgium', 'Bosnia And Herzegovina',\n",
       "       'Hungary', 'Norway', 'Finland', 'Sweden', 'Austria', 'Turkey',\n",
       "       'Tunisia', 'Macedonia', 'Estonia', 'Moldova', 'Albania', 'Ireland',\n",
       "       'Switzerland', 'Slovakia', 'Slovenia', 'Iceland', 'Algeria',\n",
       "       'Libya', 'Morocco', 'Bahamas', 'Kazakhstan', 'Armenia', 'Georgia',\n",
       "       'Madagascar', 'Mozambique', 'Mauritius', 'Reunion', 'Egypt',\n",
       "       'Syria', 'Cyprus', 'Lebanon', 'India', 'Pakistan', 'Bangladesh',\n",
       "       'Burma', 'Sri Lanka', 'Nepal', 'Indonesia', 'Israel', 'Iran',\n",
       "       'Azerbaijan', 'Iraq', 'Jordan', 'Turkmenistan', 'Uzbekistan',\n",
       "       'China', 'Laos', 'Thailand', 'Saudi Arabia', 'Mongolia', 'Mexico',\n",
       "       'Cuba', 'Haiti', 'Venezuela', 'Colombia', 'Brazil',\n",
       "       'Dominican Republic', 'Jamaica', 'Guyana', 'Puerto Rico',\n",
       "       'Suriname', 'Vietnam', 'Malaysia', 'Honduras', 'Singapore',\n",
       "       'Cambodia', 'Panama', 'Nicaragua', 'Philippines', 'Guatemala',\n",
       "       'Argentina', 'Paraguay', 'Uruguay', 'Tajikistan', 'Afghanistan',\n",
       "       'El Salvador', 'Japan', 'South Korea', 'Hong Kong', 'Taiwan',\n",
       "       'Australia', 'New Zealand', 'Bahrain', 'United Arab Emirates',\n",
       "       'Qatar', 'Benin', 'Togo', 'Guinea', 'Ghana', 'Guinea Bissau',\n",
       "       \"Côte D'Ivoire\", 'Senegal', 'Sierra Leone', 'Gambia', 'Liberia',\n",
       "       'Mauritania', 'Burkina Faso', 'Mali', 'Niger', 'Nigeria',\n",
       "       'Congo (Democratic Republic Of The)', 'Zambia', 'Tanzania',\n",
       "       'Malawi', 'Ethiopia', 'Uganda', 'Zimbabwe', 'Rwanda', 'Kenya',\n",
       "       'Burundi', 'Somalia', 'Sudan', 'Costa Rica', 'Ecuador', 'Peru',\n",
       "       'Chile', 'Bolivia', 'Central African Republic', 'Cameroon',\n",
       "       'Gabon', 'Chad', 'Angola', 'Equatorial Guinea', 'Congo',\n",
       "       'South Africa', 'Lesotho', 'Botswana', 'Namibia', 'Swaziland',\n",
       "       'Djibouti', 'Eritrea', 'Yemen', 'Oman', 'Papua New Guinea'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_df[\"Country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Mali</td>\n",
       "      <td>27.59</td>\n",
       "      <td>15.27N</td>\n",
       "      <td>4.17W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>27.82</td>\n",
       "      <td>12.05N</td>\n",
       "      <td>1.64W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Sudan</td>\n",
       "      <td>28.07</td>\n",
       "      <td>8.84N</td>\n",
       "      <td>31.62E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Niger</td>\n",
       "      <td>28.15</td>\n",
       "      <td>13.66N</td>\n",
       "      <td>2.48E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Djibouti</td>\n",
       "      <td>29.15</td>\n",
       "      <td>12.05N</td>\n",
       "      <td>42.74E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country  AverageTemperature Latitude Longitude\n",
       "89           Mali               27.59   15.27N     4.17W\n",
       "20   Burkina Faso               27.82   12.05N     1.64W\n",
       "133         Sudan               28.07    8.84N    31.62E\n",
       "103         Niger               28.15   13.66N     2.48E\n",
       "40       Djibouti               29.15   12.05N    42.74E"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_temp = df_temp.groupby(['Country']) \\\n",
    "                            .agg({\"AverageTemperature\": \"mean\", \n",
    "                                  \"Latitude\": \"first\", \n",
    "                                  \"Longitude\": \"first\"}).reset_index()\n",
    "                            \n",
    "global_temp.sort_values([\"AverageTemperature\"], ascending=True, inplace=True)\n",
    "global_temp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c/c: Temperature from 1743 to 2013, useful if we want look for raison of immigration. People have needed bad weather conditions for a long time to leave their country**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airports Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data from ? see udacity\n",
    "* code used in passenger reservation, ticket and baggage-handling\n",
    "* definition IATA\n",
    "* definition ISO\n",
    "* GPS code of airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    * remplir les points precedents\n",
    "    * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 55075 rows and 12 columns in DataFrame df_airport_world.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ident         55075 non-null  object \n",
      " 1   type          55075 non-null  object \n",
      " 2   name          55075 non-null  object \n",
      " 3   elevation_ft  48069 non-null  float64\n",
      " 4   continent     27356 non-null  object \n",
      " 5   iso_country   54828 non-null  object \n",
      " 6   iso_region    55075 non-null  object \n",
      " 7   municipality  49399 non-null  object \n",
      " 8   gps_code      41030 non-null  object \n",
      " 9   iata_code     9189 non-null   object \n",
      " 10  local_code    28686 non-null  object \n",
      " 11  coordinates   55075 non-null  object \n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>00AS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AS</td>\n",
       "      <td>-97.8180194, 34.9428028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00AZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cordes Airport</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AZ</td>\n",
       "      <td>Cordes</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>-112.16500091552734, 34.305599212646484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00CA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goldstone /Gts/ Airport</td>\n",
       "      <td>3038.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Barstow</td>\n",
       "      <td>00CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00CA</td>\n",
       "      <td>-116.888000488, 35.350498199499995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00CL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Williams Ag Airport</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Biggs</td>\n",
       "      <td>00CL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00CL</td>\n",
       "      <td>-121.763427, 39.427188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00CN</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Kitchen Creek Helibase Heliport</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Pine Valley</td>\n",
       "      <td>00CN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00CN</td>\n",
       "      <td>-116.4597417, 32.7273736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "5  00AS  small_airport                      Fulton Airport        1100.0   \n",
       "6  00AZ  small_airport                      Cordes Airport        3810.0   \n",
       "7  00CA  small_airport             Goldstone /Gts/ Airport        3038.0   \n",
       "8  00CL  small_airport                 Williams Ag Airport          87.0   \n",
       "9  00CN       heliport     Kitchen Creek Helibase Heliport        3350.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "5       NaN          US      US-OK          Alex     00AS       NaN   \n",
       "6       NaN          US      US-AZ        Cordes     00AZ       NaN   \n",
       "7       NaN          US      US-CA       Barstow     00CA       NaN   \n",
       "8       NaN          US      US-CA         Biggs     00CL       NaN   \n",
       "9       NaN          US      US-CA   Pine Valley     00CN       NaN   \n",
       "\n",
       "  local_code                              coordinates  \n",
       "0        00A       -74.93360137939453, 40.07080078125  \n",
       "1       00AA                   -101.473911, 38.704022  \n",
       "2       00AK              -151.695999146, 59.94919968  \n",
       "3       00AL    -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                      -91.254898, 35.6087  \n",
       "5       00AS                  -97.8180194, 34.9428028  \n",
       "6       00AZ  -112.16500091552734, 34.305599212646484  \n",
       "7       00CA       -116.888000488, 35.350498199499995  \n",
       "8       00CL                   -121.763427, 39.427188  \n",
       "9       00CN                 -116.4597417, 32.7273736  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# airport-codes_csv UDACITY\n",
    "nRowsRead = None # change and set to None for the whole data\n",
    "description      = \"airport-codes_csv provide by UDACITY\"\n",
    "name             = \"df_airport_world\"\n",
    "file             = \"airport-codes_csv.csv\"\n",
    "\n",
    "n_df             = pd.read_csv(path+file, sep=\",\", nrows = nRowsRead)\n",
    "nRow, nCol       = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_airport_world = n_df\n",
    "\n",
    "#dic_4 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "print(n_df.info())\n",
    "n_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "\n",
    "Column Name | Description | Example | Type\n",
    "-|-|-|-|\n",
    "**ident**| Unique identifier| 00AK| object \n",
    "**type**| Type of airport | small_airport |object\n",
    "**name**| Name of the airport | Lowell Field | object\n",
    "**elevation_ft**| Altitude of the airport |11.0 |float\n",
    "**continent**| Continent | | object\n",
    "**iso_country**| ISO code of airport country |US| object\n",
    "**iso_region**| ISO code of the region airport | US-KS|object\n",
    "**municipality**| City name where the airport is located | Anchor Point|object\n",
    "**gps_code**| GPS code of the airport | 00AK|object\n",
    "**iata_code**| IATA code of the airport| | object\n",
    "**local_code**| Local code airport |00AK | object\n",
    "**coordinates**|  \tGPS coordinates of the airport | -151.695999146, 59.94919968 | object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing and Duplicate\n",
    "* no duplicate for the whole Airports dataset\n",
    "* column `ident` has no missing value and unique.\n",
    "* none value 45886 in iata_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ident, type, name, elevation_ft, continent, iso_country, iso_region, municipality, gps_code, iata_code, local_code, coordinates]\n",
       "Index: []"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup = n_df[n_df.duplicated(keep=False)].sort_values(\"ident\")\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident           55075\n",
       "type                7\n",
       "name            52144\n",
       "elevation_ft     5449\n",
       "continent           6\n",
       "iso_country       243\n",
       "iso_region       2810\n",
       "municipality    27133\n",
       "gps_code        40850\n",
       "iata_code        9042\n",
       "local_code      27436\n",
       "coordinates     54874\n",
       "dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elevation_ft     7006\n",
      "continent       27719\n",
      "iso_country       247\n",
      "municipality     5676\n",
      "gps_code        14045\n",
      "iata_code       45886\n",
      "local_code      26389\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   elevation_ft continent iso_country  municipality gps_code iata_code  \\\n",
       "0          11.0       NaN          US      Bensalem      00A       NaN   \n",
       "1        3435.0       NaN          US         Leoti     00AA       NaN   \n",
       "2         450.0       NaN          US  Anchor Point     00AK       NaN   \n",
       "3         820.0       NaN          US       Harvest     00AL       NaN   \n",
       "4         237.0       NaN          US       Newport      NaN       NaN   \n",
       "\n",
       "  local_code  \n",
       "0        00A  \n",
       "1       00AA  \n",
       "2       00AK  \n",
       "3       00AL  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [col for col in n_df.columns if n_df[col].isnull().any()]\n",
    "df_miss = n_df[cols]\n",
    "print(df_miss.isna().sum())\n",
    "df_miss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ident, type, name, elevation_ft, continent, iso_country, iso_region, municipality, gps_code, iata_code, local_code, coordinates]\n",
       "Index: []"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = n_df[n_df.apply(lambda x: x.astype(str).str.contains(r'\\bUS-HI\\b')).any(axis=1)]\n",
    "df = df1[df1.apply(lambda x: x.astype(str).str.contains('HHW')).any(axis=1)]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c/c : It seems to have no data in common apart from the regions of the united states with the 1st dataset.The columns `ident` contains unique value for airport, digit letter with zero before, sometimes 1 or 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US Cities Demographic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* from the US census bureau's\n",
    "* demographics of all US cities > 65 000\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TOOLS BOX\n",
    "--------------------------------------------------------------------------------------\n",
    "# airport-codes_csv UDACITY\n",
    "nRowsRead = None # change and set to None for the whole data\n",
    "description      = \"airport-codes_csv provide by UDACITY\"\n",
    "name             = \"df_airport_world\"\n",
    "file             = \"airport-codes_csv.csv\"\n",
    "n_df             = pd.read_csv(path+file, sep=\",\", nrows = nRowsRead)\n",
    "nRow, nCol       = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_airport_world = n_df\n",
    "#dic_4 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "\n",
    "print(n_df.info())\n",
    "n_df.head(10)\n",
    "----------------------------------------\n",
    "\n",
    "### Data dictionary\n",
    "Column Name | Description | Example | Type\n",
    "-|-|-|-|\n",
    "----------------------------------------\n",
    "# RETROUVER UNE CHAINE DE CARACTERE\n",
    "n_df[n_df['iata_code'].str.contains(r'\\b00A\\b')]\n",
    "----------------------------------------\n",
    "# PRETTY PRINT\n",
    "n_df = pd.read_csv(path+file, nrows = nRowsRead)\n",
    "nRow, nCol = n_df.shape\n",
    "print(\"There are {} rows and {} columns in {}.\".format(nRow, nCol, description))\n",
    "df_immigration = n_d\n",
    "----------------------------------------\n",
    "# DATAFRAME AVEC LES COLNNES AVEC NULL VALUE\n",
    "cols = [col for col in n_df.columns if n_df[col].isnull().any()]\n",
    "df_miss = n_df[cols]\n",
    "df_miss.nunique()\n",
    "df_miss[pd.isnull(df_miss).any(axis=1)]\n",
    "----------------------------------------\n",
    "df.apply(lambda row: row.astype(str).str.contains('TEST').any(), axis=1)\n",
    "----------------------------------------\n",
    "n = n_df.dropna()\n",
    "----------------------------------------\n",
    "df = n_df[n_df.apply(lambda x: x.astype(str).str.contains(r'\\bHHW\\b')).any(axis=1)]\n",
    "----------------------------------------\n",
    "duplicateRowsDF = n_df[n_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2891 rows and 12 columns in DataFrame df_demograph.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   City                    2891 non-null   object \n",
      " 1   State                   2891 non-null   object \n",
      " 2   Median Age              2891 non-null   float64\n",
      " 3   Male Population         2888 non-null   float64\n",
      " 4   Female Population       2888 non-null   float64\n",
      " 5   Total Population        2891 non-null   int64  \n",
      " 6   Number of Veterans      2878 non-null   float64\n",
      " 7   Foreign-born            2878 non-null   float64\n",
      " 8   Average Household Size  2875 non-null   float64\n",
      " 9   State Code              2891 non-null   object \n",
      " 10  Race                    2891 non-null   object \n",
      " 11  Count                   2891 non-null   int64  \n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>33.1</td>\n",
       "      <td>56229.0</td>\n",
       "      <td>62432.0</td>\n",
       "      <td>118661</td>\n",
       "      <td>6634.0</td>\n",
       "      <td>7517.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>IL</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avondale</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>29.1</td>\n",
       "      <td>38712.0</td>\n",
       "      <td>41971.0</td>\n",
       "      <td>80683</td>\n",
       "      <td>4815.0</td>\n",
       "      <td>8355.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>11592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Covina</td>\n",
       "      <td>California</td>\n",
       "      <td>39.8</td>\n",
       "      <td>51629.0</td>\n",
       "      <td>56860.0</td>\n",
       "      <td>108489</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>37038.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>32716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O'Fallon</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41762.0</td>\n",
       "      <td>43270.0</td>\n",
       "      <td>85032</td>\n",
       "      <td>5783.0</td>\n",
       "      <td>3269.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>MO</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High Point</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>35.5</td>\n",
       "      <td>51751.0</td>\n",
       "      <td>58077.0</td>\n",
       "      <td>109828</td>\n",
       "      <td>5204.0</td>\n",
       "      <td>16315.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asian</td>\n",
       "      <td>11060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City           State  Median Age  Male Population  \\\n",
       "0     Silver Spring        Maryland        33.8          40601.0   \n",
       "1            Quincy   Massachusetts        41.0          44129.0   \n",
       "2            Hoover         Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga      California        34.5          88127.0   \n",
       "4            Newark      New Jersey        34.6         138040.0   \n",
       "5            Peoria        Illinois        33.1          56229.0   \n",
       "6          Avondale         Arizona        29.1          38712.0   \n",
       "7       West Covina      California        39.8          51629.0   \n",
       "8          O'Fallon        Missouri        36.0          41762.0   \n",
       "9        High Point  North Carolina        35.5          51751.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "5            62432.0            118661              6634.0        7517.0   \n",
       "6            41971.0             80683              4815.0        8355.0   \n",
       "7            56860.0            108489              3800.0       37038.0   \n",
       "8            43270.0             85032              5783.0        3269.0   \n",
       "9            58077.0            109828              5204.0       16315.0   \n",
       "\n",
       "   Average Household Size State Code                               Race  Count  \n",
       "0                    2.60         MD                 Hispanic or Latino  25924  \n",
       "1                    2.39         MA                              White  58723  \n",
       "2                    2.58         AL                              Asian   4759  \n",
       "3                    3.18         CA          Black or African-American  24437  \n",
       "4                    2.73         NJ                              White  76402  \n",
       "5                    2.40         IL  American Indian and Alaska Native   1343  \n",
       "6                    3.18         AZ          Black or African-American  11592  \n",
       "7                    3.56         CA                              Asian  32716  \n",
       "8                    2.77         MO                 Hispanic or Latino   2583  \n",
       "9                    2.65         NC                              Asian  11060  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# us-cities-demographics USACITY\n",
    "nRowsRead = None # change and set to None for the whole data\n",
    "description   = \"us-cities-demographics provide by UDACITY\"\n",
    "name          = \"df_demograph\"\n",
    "file          = \"us-cities-demographics.csv\"\n",
    "\n",
    "n_df          = pd.read_csv(path+file, sep=\";\", nrows = nRowsRead)\n",
    "nRow, nCol    = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_demograph  = n_df\n",
    "print(n_df.info())\n",
    "n_df.head(10)\n",
    "# dic_5 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "Column Name | Description | Example | Type\n",
    "-|-|-|-|\n",
    "**City**|City Name|High Point|object\n",
    "**State**|State Name|North Carolina|object\n",
    "**Median Age**| The median age of the population | 35.5| float64\n",
    "**Male Population**| Number of male | 51751.0 | float64\n",
    "**Female Population** | Number of female | 58077.0 |float64\n",
    "**Total Population** | Number of toatal population |109828| int64\n",
    "**Number of Veterans**| Number of veterans |5204.0| float64\n",
    "**Foreign-born**| Number of residents of the city that were not born (in us)| 16315.0| float64\n",
    "**Average Household Size**| The average of people in a household| 2.65| float64\n",
    "**State Code**| The code of the state of the city| NC | object\n",
    "**Race**|Race class |Asian| object\n",
    "**Count**|Number of individual of each race|11060|int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### missing and duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [City, State, Median Age, Male Population, Female Population, Total Population, Number of Veterans, Foreign-born, Average Household Size, State Code, Race, Count]\n",
       "Index: []"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup = n_df[n_df.duplicated(keep=False)].sort_values(\"City\")\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>2.93e+04</td>\n",
       "      <td>3.39e+04</td>\n",
       "      <td>4225.0</td>\n",
       "      <td>7.38e+03</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2.93e+04</td>\n",
       "      <td>3.39e+04</td>\n",
       "      <td>4225.0</td>\n",
       "      <td>7.38e+03</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>2.93e+04</td>\n",
       "      <td>3.39e+04</td>\n",
       "      <td>4225.0</td>\n",
       "      <td>7.38e+03</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>2.93e+04</td>\n",
       "      <td>3.39e+04</td>\n",
       "      <td>4225.0</td>\n",
       "      <td>7.38e+03</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>2.93e+04</td>\n",
       "      <td>3.39e+04</td>\n",
       "      <td>4225.0</td>\n",
       "      <td>7.38e+03</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>4.08e+06</td>\n",
       "      <td>4.47e+06</td>\n",
       "      <td>156961.0</td>\n",
       "      <td>3.21e+06</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>4.08e+06</td>\n",
       "      <td>4.47e+06</td>\n",
       "      <td>156961.0</td>\n",
       "      <td>3.21e+06</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15231.0</td>\n",
       "      <td>4.03e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15231.0</td>\n",
       "      <td>4.03e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15231.0</td>\n",
       "      <td>4.03e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2889 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Male Population  Female Population  Number of Veterans  Foreign-born  \\\n",
       "2458         2.93e+04           3.39e+04              4225.0      7.38e+03   \n",
       "307          2.93e+04           3.39e+04              4225.0      7.38e+03   \n",
       "1786         2.93e+04           3.39e+04              4225.0      7.38e+03   \n",
       "567          2.93e+04           3.39e+04              4225.0      7.38e+03   \n",
       "1648         2.93e+04           3.39e+04              4225.0      7.38e+03   \n",
       "...               ...                ...                 ...           ...   \n",
       "1826         4.08e+06           4.47e+06            156961.0      3.21e+06   \n",
       "2494         4.08e+06           4.47e+06            156961.0      3.21e+06   \n",
       "333               NaN                NaN             15231.0      4.03e+03   \n",
       "449               NaN                NaN             15231.0      4.03e+03   \n",
       "1437              NaN                NaN             15231.0      4.03e+03   \n",
       "\n",
       "      Average Household Size  \n",
       "2458                    2.39  \n",
       "307                     2.39  \n",
       "1786                    2.39  \n",
       "567                     2.39  \n",
       "1648                    2.39  \n",
       "...                      ...  \n",
       "1826                    2.68  \n",
       "2494                    2.68  \n",
       "333                      NaN  \n",
       "449                      NaN  \n",
       "1437                     NaN  \n",
       "\n",
       "[2889 rows x 5 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [col for col in n_df.columns if n_df[col].isnull().any()]\n",
    "df_miss = n_df[cols]\n",
    "df_miss.head()\n",
    "df_miss[pd.isnull(df_miss).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [City, State, Median Age, Male Population, Female Population, Total Population, Number of Veterans, Foreign-born, Average Household Size, State Code, Race, Count]\n",
       "Index: []"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicateRowsDF = n_df[n_df.duplicated()]\n",
    "duplicateRowsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airports_us.csv KAGGLE\n",
    "nRowsRead = None # change and set to None for the whole data\n",
    "description = \" Dataset from KAGGLE, usefule to follow where go aliens\"\n",
    "name = \"df_airport_us\"\n",
    "file = \"airports_us.csv\"\n",
    "n_df = pd.read_csv(path+file, nrows = nRowsRead)\n",
    "nRow, nCol = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, file))\n",
    "df_airport_us = n_df\n",
    "df_airport_us.head()\n",
    "#print(n_df.head(1))\n",
    "#print(n_df.info())\n",
    "#dic_1 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "#dic_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WDIData.csv Indicators developpement KAGGLE\n",
    "description      = \"WDIData.csv country Indicators developpment KAGGLE\"\n",
    "name             = \"df_indicator_dev\"\n",
    "file             = \"WDIData.csv\"\n",
    "\n",
    "n_df             = pd.read_csv(path+file, sep=\",\", nrows = nRowsRead)\n",
    "nRow, nCol       = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_indicator_dev = n_df\n",
    "\n",
    "dic_3 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "# dic_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I94 DESCRIPTION\n",
    "description   = \"I94_SAS_Labels_Descriptions.SAS\"\n",
    "name          = \"df_label_I94\"\n",
    "file          = \"I94_SAS_Labels_Descriptions.SAS\"\n",
    "\n",
    "n_df          = pd.read_csv(path+file, sep=\",\", nrows = nRowsRead)\n",
    "nRow, nCol    = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_<>       = n_df\n",
    "\n",
    "dic_<> = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "dic_<>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAS\n",
    "description   = \" Some parquet files in directory 'sas_data'\"\n",
    "name          = \"df_sas\"\n",
    "file          = \"./dataset/sas_data\"\n",
    "\n",
    "n_df          = spark.read.parquet(\"./dataset/sas_data\")\n",
    "nRow, nCol    = n_df.count(), len(n_df.columns)\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_sas        = n_df\n",
    "\n",
    "dic_8 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "#dic_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./dataset/20-years-us-university-dataset\n",
    "# decide to not use it for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./dataset/airline-delay-and-cancellation-data-2009-2018/2016.csv\n",
    "description   = \".Data about us flight in 2016\"\n",
    "name          = \"df_airline_delay\"\n",
    "file          = \"airline-delay-and-cancellation-data-2009-2018/2016.csv\"\n",
    "\n",
    "n_df          = pd.read_csv(path+file, nrows = nRowsRead)\n",
    "nRow, nCol    = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_airline_delay       = n_df\n",
    "\n",
    "dic_10 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "#dic_10\n",
    "type(dic_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dic = [dic_1, dic_2, dic_3, dic_4, dic_5, dic_6, dic_8, dic_9, dic_10]\n",
    "\n",
    "description   =\n",
    "name          =\n",
    "file          =\n",
    "\n",
    "n_df          = pd.read_csv(path+file, sep=\",\", nrows = nRowsRead)\n",
    "nRow, nCol    = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_temp       = n_df\n",
    "\n",
    "dic_n = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "dic_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /dataset/education-statistics \n",
    "\n",
    "description           = \"Data from education-statistics\"\n",
    "name                  = \"df_Educ_country_series\"\n",
    "file                  = \"education-statistics/EdStatsCountry-Series.csv\"\n",
    "n_df                  = pd.read_csv(path+file, sep=\",\", nrows = nRowsRead)\n",
    "nRow, nCol            = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_Educ_country_series = n_df\n",
    "dic_11 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "#dic_11\n",
    "\n",
    "description   = \"Data from education-statistics\"\n",
    "name          = \"df_Educ_country\"\n",
    "file          = \"education-statistics/EdStatsCountry.csv\"\n",
    "n_df          = pd.read_csv(path+file, sep=\",\", nrows = nRowsRead)\n",
    "nRow, nCol    = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_Educ_country = n_df\n",
    "dic_12 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "#dic_12\n",
    "\n",
    "description   = \"Data from education-statistics\"\n",
    "name          = \"df_Educ_data\"\n",
    "file          = \"education-statistics/EdStatsData.csv\"\n",
    "n_df          = pd.read_csv(path+file, nrows = nRowsRead)\n",
    "nRow, nCol    = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_Educ_data  = n_df\n",
    "dic_13 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "#dic_13\n",
    "\n",
    "description       = \"Data from education-statistics\"\n",
    "name              = \"df_Educ_foot_note\"\n",
    "file              = \"education-statistics/EdStatsFootNote.csv\"\n",
    "n_df              = pd.read_csv(path+file, sep=\",\", nrows = nRowsRead)\n",
    "nRow, nCol        = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_Educ_foot_note = n_df\n",
    "dic_14 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "#dic_14\n",
    "\n",
    "description    = \"Data from education-statistics\"\n",
    "name           = \"df_Educ_series\"\n",
    "file           = \"education-statistics/EdStatsSeries.csv\"\n",
    "n_df           = pd.read_csv(path+file, sep=\",\", nrows = nRowsRead)\n",
    "nRow, nCol     = n_df.shape\n",
    "print(\"There are {} rows and {} columns in DataFrame {}.\".format(nRow, nCol, name))\n",
    "df_Educ_series = n_df\n",
    "dic_15 = {'name': name, 'path': (path+file), 'nLines': nRow, 'nColomn': nCol, 'Description': description}\n",
    "#dic_15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dic1 = [dic_1, dic_2, dic_3, dic_4, dic_5, dic_6, dic_8, dic_10, dic_11, dic_12, dic_13]\n",
    "for dic in list_dic1:\n",
    "    print(type(dic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%xdel n_df\n",
    "%who_ls dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%whos DataFrame\n",
    "all_df = %who_ls DataFrame\n",
    "all_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_sas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_immigration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_indicator_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_country_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_foot_note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_df_demograph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_airport_world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_airport_us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_airline_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airline_delay.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airline_delay.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df_airline_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airline_delay.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_airline_delay.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airline_delay.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_airline_delay.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airline_delay.describe(include=np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
